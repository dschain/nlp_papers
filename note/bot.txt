
1.对话系统
问答型
	检索式闲聊，完成FAQ型问答
	CoQA[22] benchmark上的近期工作以及一些KB Dialogue
	EMNLP2016 百度自然语言处理部的xiangyang大佬的Multi-view[1]

	ACL2017 MSRA吴俣大佬的SMN[2]

	COLING2018 上交的DUA[3]

	ACL2018 百度自然语言处理部xiangyang大佬和lilu女神的DAM[4]

任务型
闲聊型

ADEM[17]，RUBER[18]
信息检索模型如BM25以及一些轻量级文本特征表示模型如bow就派上用场了
AnyQ
在多轮对话匹配这一方面百度的对话团队做了大量的工作，属于长期霸榜的状态，比如Multi-view[7]、DAM[8]以及DGU[9]。最新的DGU刷爆了去年的DAM 9个点了╮(￣▽￣"")

很多文章开篇就会告诉你一个任务型对话系统包括NLU、DST、DP、NLG等模块。而实际上这种pipeline的方式虽然经典而常用，但是带来的问题也很多，都9012年了，自然诞生了很多joint training甚至end2end的方法将pipeline中的各个模块连接起来。下面慢慢来看一下。

如今的意图识别与槽位解析的SOTA方法应该就是百度对话团队的DGU[9]了

一、基于规则的简单聊天机器人
		规则+知识图谱
二、检索类聊天机器人
		Chatterbot	需要数据库比较大，回答比较自然 固定领域的应用、开放领域的应用
		提问 - 检索 - 答案抽取
		关键技术--检索匹配
			基于检索的技术
				余弦相似度cos(Q)
				皮尔森相关系数
				TF-IDF
			基于模式匹配的技术
			基于自然语言理解的技术
			基于统计翻译模型的技术
		Chatterbot
			storage_adapters
			logic_adapter
				trainer
				bot.train([,,,,,,])
			response=bot.get_reponse('')
三、生成式聊天机器人
		Seq2Seq+Attention
		SeqGAN和强化学习
			SeqGAN ，学术阶段
				
四、聊天机器人模型技术发展方向
		GAN对抗生成网络
			从2017年开始火起来，CV用的多	
		DQN深度强化学习网
			alphago开始火起来，游戏用的多
		GNN图神经网络
			
neo4j调优，百万级没问题
增加索引，索引创建后一定要ONLINE才会生效
优化neo4j配置文件
增加服务器内存
增加ssd固态硬盘
学会优化Cypher查询语句
购买企业版，搭建集群。社区版不适合用在生产环境
在业务逻辑上拆分数据，分别放在运行在不同电脑上的neo4j实例上（如果业务逻辑上无法拆分，就不要考虑了）
不必要的数据，尽可能早的过滤掉，减少后期处理的数据量
不必要的数据，不要放进图中，和mysql结合使用
避免返回整个节点，返回其中需要的数据
分库存储，充分利用neo4j的图存储和查询特点，neo4j中只提供图的存储和查询功能，节点的属性信息保存在mongodb（或其他NoSql 数据库中---字段可以直接存储）进行关联查询，各取所长，充分利优势，优化性能；	
